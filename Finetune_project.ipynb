{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygh4qCAGBwcy"
      },
      "outputs": [],
      "source": [
        "from github import Github\n",
        "import re\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "g = Github(\"private\")\n",
        "\n",
        "\n",
        "repo = g.get_repo(\"openai/gym\")\n",
        "\n",
        "\n",
        "def extract_functions_from_code(code):\n",
        "    pattern = re.compile(r\"def\\s+(\\w+)\\s*\\(.*\\):\")\n",
        "    functions = pattern.findall(code)\n",
        "    return functions\n",
        "\n",
        "\n",
        "python_files = []\n",
        "contents = repo.get_contents(\"\")\n",
        "while contents:\n",
        "    file_content = contents.pop(0)\n",
        "    if file_content.type == \"dir\":\n",
        "        contents.extend(repo.get_contents(file_content.path))\n",
        "    elif file_content.path.endswith(\".py\"):\n",
        "        python_files.append(file_content)\n",
        "\n",
        "\n",
        "data = {\"code\": [], \"function_name\": []}\n",
        "for file in python_files:\n",
        "    code = file.decoded_content.decode(\"utf-8\")\n",
        "    functions = extract_functions_from_code(code)\n",
        "    for function in functions:\n",
        "        data[\"code\"].append(code)\n",
        "        data[\"function_name\"].append(function)\n",
        "\n",
        "\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "\n",
        "dataset.save_to_disk(\"code_generation_dataset\")\n",
        "\n",
        "print(\"Dataset created and saved to disk.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeTyiFOkCFDZ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
        "\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# load the dataset\n",
        "dataset = load_from_disk(\"code_generation_dataset\")\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['code'], truncation=True, padding='max_length')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrONc4oCCLAs"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# fine-tune the model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test']\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7WNWys-CT4H"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_code(prompt, max_length=100):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs['input_ids'], max_length=max_length)\n",
        "    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_code\n",
        "\n",
        "\n",
        "prompt = \"def merge_sort(arr):\"\n",
        "generated_code = generate_code(prompt)\n",
        "\n",
        "print(\"Generated Code:\")\n",
        "print(generated_code)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
